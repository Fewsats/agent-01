{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ant\n",
    "\n",
    "> Meta Tools for AI agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import requests\n",
    "from cosette import contents, Chat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting L402 URI Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_l402_uri_info(uri: str) -> dict:\n",
    "    \"\"\"\n",
    "   Returns the information of the L402 URI resource.\n",
    "\n",
    "    Args:\n",
    "    uri (str): The L402 URI to describe.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the description of the L402 URI.\n",
    "    \"\"\"\n",
    "    if not uri.startswith(\"l402://\"):\n",
    "        raise ValueError(\"Invalid L402 URI format\")\n",
    "    \n",
    "    scheme = \"http://\" if \"localhost\" in uri else \"https://\"\n",
    "    http_url = uri.replace(\"l402://\", scheme, 1)\n",
    "    \n",
    "    response = requests.get(http_url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'access': {'endpoint': 'https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9',\n",
       "  'method': 'POST'},\n",
       " 'content_type': 'api',\n",
       " 'cover_url': '',\n",
       " 'description': 'Scrape a given URL. Pass the URL as JSON in the request body as follows:\\n```\\n {\"url\": url }\\n```',\n",
       " 'name': 'Web Scraper TF',\n",
       " 'pricing': [{'amount': 1, 'currency': 'USD'}],\n",
       " 'version': '0.1'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uri = \"l402://api.fewsats.com/v0/gateway/f12e5deb-b07b-4af4-a4f2-3fbf076228a9/info\" # web scraping endpoint\n",
    "\n",
    "info = get_l402_uri_info(uri)\n",
    "info['access'].pop('authentication', None)\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Python Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import json \n",
    "\n",
    "func_generation_sp = \"\"\"You are an AI assistant specialized in creating Python functions based on L402 info inputs. \n",
    "When given an L402 info dictionary, your task is to generate a Python function that can access the specified endpoint. \n",
    "Follow these guidelines:\n",
    "\n",
    "1. Create a function name that relates to the resource or action described in the 'name' field making it specific enough to avoid conflicts.\n",
    "2. Use the 'endpoint' field to determine the URL for the request.\n",
    "3. Use the 'method' field to determine the HTTP method for the request.\n",
    "4. Handle any required parameters for the endpoint request by passing them as function params.\n",
    "5. Write a docstring that includes:\n",
    "   - A brief description of the function's purpose\n",
    "   - Parameters with their types and descriptions\n",
    "   - Return value with its type and description\n",
    "6. Do not import the requests library. Assume it is available in the global scope.\n",
    "7. Handle potential errors and exceptions appropriately.\n",
    "8. Do not handle any authentication or authorization in the function.\n",
    "9. Return the response from the endpoint.\n",
    "10. Use L402 request client to send the request and configure exactly like this:\n",
    "\n",
    "L402 Request configuration:\n",
    "```\n",
    "l402_requests.configure(\n",
    "   preimage_provider=AlbyAPI(api_key=os.getenv(\"ALBY_TOKEN\")),\n",
    "   credentials_service=SqliteCredentialsService(\":memory:\")\n",
    ")\n",
    "```\n",
    "\n",
    "Example input:\n",
    "```\n",
    "{'access': {'authentication': {'format': 'L402 {credentials}:{proof_of_payment}',\n",
    "   'header': 'Authorization',\n",
    "   'protocol': 'L402'},\n",
    "  'endpoint': 'https://blockbuster.fewsats.com/video/stream/79c816f77fdc4e66b8cd18ad67537936',\n",
    "  'method': 'POST'},\n",
    " 'content_type': 'video',\n",
    " 'cover_url': 'https://pub-3c55410f5c574362bbaa52948499969e.r2.dev/cover-images/79c816f77fdc4e66b8cd18ad67537936',\n",
    " 'description': 'Lex Fridman Podcast full episode:    â€¢ Andrew Huberman: Focus, Controversy, ',\n",
    " 'name': 'How to focus and think deeply | Andrew Huberman and Lex Fridman',\n",
    " 'pricing': [{'amount': 1, 'currency': 'USD'}],\n",
    " 'version': '1.0'}\n",
    "```\n",
    "\n",
    "Example output:\n",
    "```\n",
    "from l402.client import requests as l402_requests\n",
    "from l402.client.preimage_provider import AlbyAPI\n",
    "from l402.client.credentials import SqliteCredentialsService\n",
    "import requests\n",
    "import os\n",
    "\n",
    "l402_requests.configure(\n",
    "   preimage_provider=AlbyAPI(api_key=os.getenv(\"ALBY_TOKEN\")),\n",
    "   credentials_service=SqliteCredentialsService()\n",
    ")\n",
    " def stream_video_huberman() -> dict:\n",
    "    \\\"\\\"\\\"\n",
    "    Stream the video of the podcast episode featuring Andrew Huberman and Lex Fridman.\n",
    "\n",
    "    This function sends a POST request to the specified endpoint.\n",
    "    Returns:\n",
    "    - requests.Response: The response object containing the server's response to the request.\n",
    "    \\\"\\\"\\\"\n",
    "    endpoint = \"https://blockbuster.fewsats.com/video/stream/79c816f77fdc4e66b8cd18ad67537936\"\n",
    "    try:\n",
    "        response = l402_requests.post(endpoint, headers=headers)\n",
    "        response.raise_for_status()  # Raise an error for bad responses\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "```\n",
    "Your response should be a complete Python function definition, including imports, type hints, docstring, and function body. Only output the function definition, no other text.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def generate_python_function(info: dict) -> str:\n",
    "   \"\"\"\n",
    "   Generates a Python function based on the provided L402 info dictionary.\n",
    "\n",
    "   Args:\n",
    "   info (dict): The L402 info dictionary containing the details of the resource.\n",
    "\n",
    "   Returns:\n",
    "   str: A Python function definition as a string.\n",
    "   \"\"\"\n",
    "   # we remove authentication because it's handled by the L402 client\n",
    "   # and it only confuses the LLM\n",
    "   info['access'].pop('authentication', None)\n",
    "\n",
    "   chat = Chat('gpt-4o-mini', sp=func_generation_sp)\n",
    "   return chat(json.dumps(info))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "func_code = generate_python_function(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the function code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```python\\nfrom l402.client import requests as l402_requests\\nfrom l402.client.preimage_provider import AlbyAPI\\nfrom l402.client.credentials import SqliteCredentialsService\\nimport requests\\nimport os\\n\\nl402_requests.configure(\\n   preimage_provider=AlbyAPI(api_key=os.getenv(\"ALBY_TOKEN\")),\\n   credentials_service=SqliteCredentialsService()\\n)\\ndef scrape_web_url(url: str) -> dict:\\n    \"\"\"\\n    Scrape a given URL by sending a POST request to the specified endpoint.\\n\\n    This function sends a POST request with the URL in the request body as JSON.\\n    \\n    Parameters:\\n    - url (str): The URL to be scraped.\\n\\n    Returns:\\n    - dict: The JSON response from the server containing the scraped data.\\n    \"\"\"\\n    endpoint = \"https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9\"\\n    json_body = {\"url\": url}\\n    try:\\n        response = l402_requests.post(endpoint, json=json_body)\\n        response.raise_for_status()  # Raise an error for bad responses\\n        return response.json()\\n    except requests.exceptions.RequestException as e:\\n        print(f\"An error occurred: {e}\")\\n        return None\\n```'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = contents(func_code)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import re\n",
    "def extract_function_code(func_code):\n",
    "    code_pattern = re.compile(r'```python\\n(.*?)```', re.DOTALL)\n",
    "    match = code_pattern.search(func_code)\n",
    "    return match.group(1).strip() if match else func_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from l402.client import requests as l402_requests\n",
      "from l402.client.preimage_provider import AlbyAPI\n",
      "from l402.client.credentials import SqliteCredentialsService\n",
      "import requests\n",
      "import os\n",
      "\n",
      "l402_requests.configure(\n",
      "   preimage_provider=AlbyAPI(api_key=os.getenv(\"ALBY_TOKEN\")),\n",
      "   credentials_service=SqliteCredentialsService()\n",
      ")\n",
      "\n",
      "def web_scraper_tf(url: str) -> dict:\n",
      "    \"\"\"\n",
      "    Scrape a given URL using the Web Scraper TF service.\n",
      "\n",
      "    This function sends a POST request to the specified endpoint with the URL to scrape.\n",
      "    \n",
      "    Parameters:\n",
      "    - url (str): The URL to be scraped.\n",
      "\n",
      "    Returns:\n",
      "    - dict: The JSON response containing the result of the scraping operation.\n",
      "    \"\"\"\n",
      "    endpoint = \"https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9\"\n",
      "    headers = {'Content-Type': 'application/json'}\n",
      "    payload = {\"url\": url}\n",
      "    \n",
      "    try:\n",
      "        response = l402_requests.post(endpoint, json=payload, headers=headers)\n",
      "        response.raise_for_status()  # Raise an error for bad responses\n",
      "        return response.json()\n",
      "    except requests.exceptions.RequestException as e:\n",
      "        print(f\"An error occurred: {e}\")\n",
      "        return None\n"
     ]
    }
   ],
   "source": [
    "extracted_code = extract_function_code(response)\n",
    "print(extracted_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import importlib.util\n",
    "import re\n",
    "import os\n",
    "\n",
    "def create_func(code_string):\n",
    "    # Ensure the funcs directory exists\n",
    "    os.makedirs('.funcs', exist_ok=True)\n",
    "\n",
    "    # Extract Python code from Markdown code blocks if present\n",
    "    code_pattern = re.compile(r'```python\\n(.*?)```', re.DOTALL)\n",
    "    match = code_pattern.search(code_string)\n",
    "    extracted_code = match.group(1).strip() if match else code_string\n",
    "\n",
    "    # Create a temporary file name\n",
    "\n",
    "    function_name = extracted_code.split('def ')[1].split('(')[0].strip()\n",
    "\n",
    "    temp_file = f'.funcs/{function_name}.py'\n",
    "\n",
    "    # Write the code to a temporary file\n",
    "    with open(temp_file, 'w') as f:\n",
    "        f.write(extracted_code)\n",
    "\n",
    "    # Import the function\n",
    "    spec = importlib.util.spec_from_file_location(\"temp_module\", temp_file)\n",
    "    temp_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(temp_module)\n",
    "\n",
    "    # Get the function\n",
    "    function_name = extracted_code.split('def ')[1].split('(')[0].strip()\n",
    "    return getattr(temp_module, function_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gf = create_func(extracted_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'data': {'markdown': \"![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/66475f66cdbcb00d7bf2fd44_Employee%20data.png)\\n\\n[Learn More](#)![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n\\n\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n\\n[Learn More](#)![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n\\n\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/664773c569f5d9dbac6655a0_Employee%20data-2.png)\\n\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/664762e683491e5b21c08f31_Employee%20data-3.png)\\n\\n[Learn More](#)![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n\\n\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n\\nThe L402 protocol builds on top of HTTP and the Lightning network to enable internet-first, machine friendly paywalls.\\n\\nInternet-Native Paywalls\\n\\nThe L402 protocol builds on top of HTTP and the Lightning network to enable internet-first, machine friendly paywalls.\\n\\nL402 is an open protocol that anyone can build upon, fostering a flourishing ecosystem of innovative solutions.\\n\\nWhen the user asks about the last 'Yankees match' the response includes real-time scores, key moments, and insights from the last game.\\n\\nAmet minim mollit non deserunt est sit aliqua dolor do amet sint officia consequat duis enim mollit exercitation.\\n\\nâ†’\\n\\nAmet minim mollit non deserunt est sit aliqua dolor do amet sint officia consequat duis enim mollit exercitation.\\n\\nâ†’\\n\\nAI systems are now key consumers of software, driving demand for more intelligent, contextual data and tools. With one integration, Fewsats unlocks a universe of resources to supercharge these AI consumers.\\n\\nRevolutionize your bots with Retrieval Augmented Generation (RAG) and in-context information.\\n\\n\\nWhen the user asks about the last 'Yankees match' the response includes real-time scores, key moments, and insights from the last game.\\n\\nAmet minim mollit non deserunt est sit aliqua dolor do amet sint officia consequat duis enim mollit exercitation.\\n\\nâ†’\\n\\nAmet minim mollit non deserunt est sit aliqua dolor do amet sint officia consequat duis enim mollit exercitation.\\n\\nâ†’\\n\",\n",
       "  'metadata': {'title': 'Monetize your Files, Databases',\n",
       "   'language': None,\n",
       "   'ogLocaleAlternate': [],\n",
       "   'sourceURL': 'https://www.fewsats.com/',\n",
       "   'statusCode': 200}},\n",
       " 'error': None}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = gf('https://www.fewsats.com/')\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Tools to the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I have access to a tool that retrieves information about L402 URIs. Specifically, I can provide details about a given L402 URI by describing its properties. If you have a specific L402 URI in mind, I can help you get information about it.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-AIc5Z7maj5Kam0f8T1fxETNCeiJf6\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I have access to a tool that retrieves information about L402 URIs. Specifically, I can provide details about a given L402 URI by describing its properties. If you have a specific L402 URI in mind, I can help you get information about it.', refusal=None, role='assistant', function_call=None, tool_calls=None))]\n",
       "- created: 1728999681\n",
       "- model: gpt-4o-mini-2024-07-18\n",
       "- object: chat.completion\n",
       "- service_tier: None\n",
       "- system_fingerprint: fp_e2bde53e6e\n",
       "- usage: CompletionUsage(completion_tokens=53, prompt_tokens=111, total_tokens=164, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIc5Z7maj5Kam0f8T1fxETNCeiJf6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I have access to a tool that retrieves information about L402 URIs. Specifically, I can provide details about a given L402 URI by describing its properties. If you have a specific L402 URI in mind, I can help you get information about it.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1728999681, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_e2bde53e6e', usage=In: 111; Out: 53; Total: 164)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [get_l402_uri_info]\n",
    "chat = Chat('gpt-4o-mini', sp='You are a helpful assistant that provides information about L402 URIs and your available tools.', tools=tools)\n",
    "\n",
    "chat(\"which tools do you have available?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the information for the L402 URI `l402://api.fewsats.com/v0/gateway/f12e5deb-b07b-4af4-a4f2-3fbf076228a9/info`:\n",
       "\n",
       "- **Name**: Web Scraper TF\n",
       "- **Description**: Scrape a given URL. Pass the URL as JSON in the request body as follows:\n",
       "  ```json\n",
       "  {\"url\": url }\n",
       "  ```\n",
       "- **Content Type**: api\n",
       "- **Version**: 0.1\n",
       "- **Access**:\n",
       "  - **Authentication**:\n",
       "    - **Format**: L402 {credentials}:{proof_of_payment}\n",
       "    - **Header**: Authorization\n",
       "    - **Protocol**: L402\n",
       "  - **Endpoint**: [https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9](https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9)\n",
       "  - **Method**: POST\n",
       "- **Pricing**: \n",
       "  - **Amount**: 1\n",
       "  - **Currency**: USD\n",
       "- **Cover URL**: (not provided)\n",
       "\n",
       "If you need more information or have another URI to inquire about, feel free to ask!\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-AIc61tskvYg7i2f0fNFguyo72xTKC\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here is the information for the L402 URI `l402://api.fewsats.com/v0/gateway/f12e5deb-b07b-4af4-a4f2-3fbf076228a9/info`:\\n\\n- **Name**: Web Scraper TF\\n- **Description**: Scrape a given URL. Pass the URL as JSON in the request body as follows:\\n  ```json\\n  {\"url\": url }\\n  ```\\n- **Content Type**: api\\n- **Version**: 0.1\\n- **Access**:\\n  - **Authentication**:\\n    - **Format**: L402 {credentials}:{proof_of_payment}\\n    - **Header**: Authorization\\n    - **Protocol**: L402\\n  - **Endpoint**: [https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9](https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9)\\n  - **Method**: POST\\n- **Pricing**: \\n  - **Amount**: 1\\n  - **Currency**: USD\\n- **Cover URL**: (not provided)\\n\\nIf you need more information or have another URI to inquire about, feel free to ask!', refusal=None, role='assistant', function_call=None, tool_calls=None))]\n",
       "- created: 1728999709\n",
       "- model: gpt-4o-mini-2024-07-18\n",
       "- object: chat.completion\n",
       "- service_tier: None\n",
       "- system_fingerprint: fp_e2bde53e6e\n",
       "- usage: CompletionUsage(completion_tokens=296, prompt_tokens=483, total_tokens=779, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIc61tskvYg7i2f0fNFguyo72xTKC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here is the information for the L402 URI `l402://api.fewsats.com/v0/gateway/f12e5deb-b07b-4af4-a4f2-3fbf076228a9/info`:\\n\\n- **Name**: Web Scraper TF\\n- **Description**: Scrape a given URL. Pass the URL as JSON in the request body as follows:\\n  ```json\\n  {\"url\": url }\\n  ```\\n- **Content Type**: api\\n- **Version**: 0.1\\n- **Access**:\\n  - **Authentication**:\\n    - **Format**: L402 {credentials}:{proof_of_payment}\\n    - **Header**: Authorization\\n    - **Protocol**: L402\\n  - **Endpoint**: [https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9](https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9)\\n  - **Method**: POST\\n- **Pricing**: \\n  - **Amount**: 1\\n  - **Currency**: USD\\n- **Cover URL**: (not provided)\\n\\nIf you need more information or have another URI to inquire about, feel free to ask!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1728999709, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_e2bde53e6e', usage=In: 483; Out: 296; Total: 779)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(f'What is the info of: {uri}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L402 URI info retrieved successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'access': {'authentication': {'format': 'L402 {credentials}:{proof_of_payment}',\n",
       "   'header': 'Authorization',\n",
       "   'protocol': 'L402'},\n",
       "  'endpoint': 'https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9',\n",
       "  'method': 'POST'},\n",
       " 'content_type': 'api',\n",
       " 'cover_url': '',\n",
       " 'description': 'Scrape a given URL. Pass the URL as JSON in the request body as follows:\\n```\\n {\"url\": url }\\n```',\n",
       " 'name': 'Web Scraper TF',\n",
       " 'pricing': [{'amount': 1, 'currency': 'USD'}],\n",
       " 'version': '0.1'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Get L402 URI info\n",
    "info = get_l402_uri_info(uri)\n",
    "print(\"L402 URI info retrieved successfully.\")\n",
    "info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python function generated successfully.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from l402.client import requests as l402_requests\n",
       "from l402.client.preimage_provider import AlbyAPI\n",
       "from l402.client.credentials import SqliteCredentialsService\n",
       "import requests\n",
       "import os\n",
       "\n",
       "l402_requests.configure(\n",
       "   preimage_provider=AlbyAPI(api_key=os.getenv(\"ALBY_TOKEN\")),\n",
       "   credentials_service=SqliteCredentialsService()\n",
       ")\n",
       "def scrape_web_url(url: str) -> dict:\n",
       "    \"\"\"\n",
       "    Scrape a given URL by sending a POST request to the specified endpoint.\n",
       "\n",
       "    This function sends a POST request with the URL in the request body as JSON.\n",
       "    \n",
       "    Parameters:\n",
       "    - url (str): The URL to be scraped.\n",
       "\n",
       "    Returns:\n",
       "    - dict: The JSON response from the server containing the scraped data.\n",
       "    \"\"\"\n",
       "    endpoint = \"https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9\"\n",
       "    json_body = {\"url\": url}\n",
       "    try:\n",
       "        response = l402_requests.post(endpoint, json=json_body)\n",
       "        response.raise_for_status()  # Raise an error for bad responses\n",
       "        return response.json()\n",
       "    except requests.exceptions.RequestException as e:\n",
       "        print(f\"An error occurred: {e}\")\n",
       "        return None\n",
       "```\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-AIc69oXLPq7iRjS0ZmsxF016MRJmk\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\nfrom l402.client import requests as l402_requests\\nfrom l402.client.preimage_provider import AlbyAPI\\nfrom l402.client.credentials import SqliteCredentialsService\\nimport requests\\nimport os\\n\\nl402_requests.configure(\\n   preimage_provider=AlbyAPI(api_key=os.getenv(\"ALBY_TOKEN\")),\\n   credentials_service=SqliteCredentialsService()\\n)\\ndef scrape_web_url(url: str) -> dict:\\n    \"\"\"\\n    Scrape a given URL by sending a POST request to the specified endpoint.\\n\\n    This function sends a POST request with the URL in the request body as JSON.\\n    \\n    Parameters:\\n    - url (str): The URL to be scraped.\\n\\n    Returns:\\n    - dict: The JSON response from the server containing the scraped data.\\n    \"\"\"\\n    endpoint = \"https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9\"\\n    json_body = {\"url\": url}\\n    try:\\n        response = l402_requests.post(endpoint, json=json_body)\\n        response.raise_for_status()  # Raise an error for bad responses\\n        return response.json()\\n    except requests.exceptions.RequestException as e:\\n        print(f\"An error occurred: {e}\")\\n        return None\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))]\n",
       "- created: 1728999717\n",
       "- model: gpt-4o-mini-2024-07-18\n",
       "- object: chat.completion\n",
       "- service_tier: None\n",
       "- system_fingerprint: fp_e2bde53e6e\n",
       "- usage: CompletionUsage(completion_tokens=268, prompt_tokens=892, total_tokens=1160, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIc69oXLPq7iRjS0ZmsxF016MRJmk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\nfrom l402.client import requests as l402_requests\\nfrom l402.client.preimage_provider import AlbyAPI\\nfrom l402.client.credentials import SqliteCredentialsService\\nimport requests\\nimport os\\n\\nl402_requests.configure(\\n   preimage_provider=AlbyAPI(api_key=os.getenv(\"ALBY_TOKEN\")),\\n   credentials_service=SqliteCredentialsService()\\n)\\ndef scrape_web_url(url: str) -> dict:\\n    \"\"\"\\n    Scrape a given URL by sending a POST request to the specified endpoint.\\n\\n    This function sends a POST request with the URL in the request body as JSON.\\n    \\n    Parameters:\\n    - url (str): The URL to be scraped.\\n\\n    Returns:\\n    - dict: The JSON response from the server containing the scraped data.\\n    \"\"\"\\n    endpoint = \"https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9\"\\n    json_body = {\"url\": url}\\n    try:\\n        response = l402_requests.post(endpoint, json=json_body)\\n        response.raise_for_status()  # Raise an error for bad responses\\n        return response.json()\\n    except requests.exceptions.RequestException as e:\\n        print(f\"An error occurred: {e}\")\\n        return None\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1728999717, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_e2bde53e6e', usage=In: 892; Out: 268; Total: 1160)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Generate Python function\n",
    "func_code = generate_python_function(info)\n",
    "print(\"Python function generated successfully.\")\n",
    "func_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function code extracted successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'from l402.client import requests as l402_requests\\nfrom l402.client.preimage_provider import AlbyAPI\\nfrom l402.client.credentials import SqliteCredentialsService\\nimport requests\\nimport os\\n\\nl402_requests.configure(\\n   preimage_provider=AlbyAPI(api_key=os.getenv(\"ALBY_TOKEN\")),\\n   credentials_service=SqliteCredentialsService()\\n)\\ndef scrape_web_url(url: str) -> dict:\\n    \"\"\"\\n    Scrape a given URL by sending a POST request to the specified endpoint.\\n\\n    This function sends a POST request with the URL in the request body as JSON.\\n    \\n    Parameters:\\n    - url (str): The URL to be scraped.\\n\\n    Returns:\\n    - dict: The JSON response from the server containing the scraped data.\\n    \"\"\"\\n    endpoint = \"https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9\"\\n    json_body = {\"url\": url}\\n    try:\\n        response = l402_requests.post(endpoint, json=json_body)\\n        response.raise_for_status()  # Raise an error for bad responses\\n        return response.json()\\n    except requests.exceptions.RequestException as e:\\n        print(f\"An error occurred: {e}\")\\n        return None'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 3: Extract function code\n",
    "extracted_code = extract_function_code(get_text(func_code))\n",
    "print(\"Function code extracted successfully.\")\n",
    "extracted_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Create the function\n",
    "cf = create_func(extracted_code)\n",
    "print(\"Function created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_l402_uri_info, cf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat('gpt-4o-mini', sp='You are a helpful assistant that provides information about L402 URIs and your available tools.', tools=tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I have access to the following tools:\n",
       "\n",
       "1. **get_l402_uri_info**: This tool retrieves information about an L402 URI resource. You provide it with an L402 URI, and it returns a description of that URI.\n",
       "\n",
       "2. **scrape_web_url**: This tool scrapes a given URL by sending a POST request to a specified endpoint with the URL in the request body as JSON. It returns the JSON response containing the scraped data. \n",
       "\n",
       "If you have specific queries or tasks in mind, feel free to ask!\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-AIc6Djj1JgjClghDH50G4cn6QfUo5\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I have access to the following tools:\\n\\n1. **get_l402_uri_info**: This tool retrieves information about an L402 URI resource. You provide it with an L402 URI, and it returns a description of that URI.\\n\\n2. **scrape_web_url**: This tool scrapes a given URL by sending a POST request to a specified endpoint with the URL in the request body as JSON. It returns the JSON response containing the scraped data. \\n\\nIf you have specific queries or tasks in mind, feel free to ask!', refusal=None, role='assistant', function_call=None, tool_calls=None))]\n",
       "- created: 1728999721\n",
       "- model: gpt-4o-mini-2024-07-18\n",
       "- object: chat.completion\n",
       "- service_tier: None\n",
       "- system_fingerprint: fp_e2bde53e6e\n",
       "- usage: CompletionUsage(completion_tokens=109, prompt_tokens=194, total_tokens=303, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIc6Djj1JgjClghDH50G4cn6QfUo5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I have access to the following tools:\\n\\n1. **get_l402_uri_info**: This tool retrieves information about an L402 URI resource. You provide it with an L402 URI, and it returns a description of that URI.\\n\\n2. **scrape_web_url**: This tool scrapes a given URL by sending a POST request to a specified endpoint with the URL in the request body as JSON. It returns the JSON response containing the scraped data. \\n\\nIf you have specific queries or tasks in mind, feel free to ask!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1728999721, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_e2bde53e6e', usage=In: 194; Out: 109; Total: 303)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"which tools do you have available?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I successfully scraped the URL https://www.fewsats.com/. Here is the scraped data:\n",
       "\n",
       "### Title\n",
       "**Monetize your Files, Databases**\n",
       "\n",
       "### Content (Markdown)\n",
       "```markdown\n",
       "![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/66475f66cdbcb00d7bf2fd44_Employee%20data.png)\n",
       "\n",
       "[Learn More](#)![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\n",
       "\n",
       "![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\n",
       "[Learn More](#)![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\n",
       "\n",
       "![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\n",
       "![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/664773c569f5d9dbac6655a0_Employee%20data-2.png)\n",
       "\n",
       "![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/664762e683491e5b21c08f31_Employee%20data-3.png)\n",
       "[Learn More](#)![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\n",
       "\n",
       "The L402 protocol builds on top of HTTP and the Lightning network to enable internet-first, machine friendly paywalls.\n",
       "\n",
       "Internet-Native Paywalls\n",
       "\n",
       "The L402 protocol builds on top of HTTP and the Lightning network to enable internet-first, machine friendly paywalls.\n",
       "\n",
       "L402 is an open protocol that anyone can build upon, fostering a flourishing ecosystem of innovative solutions.\n",
       "\n",
       "AI systems are now key consumers of software, driving demand for more intelligent, contextual data and tools. With one integration, Fewsats unlocks a universe of resources to supercharge these AI consumers.\n",
       "\n",
       "**Revolutionize your bots with Retrieval Augmented Generation (RAG) and in-context information.**\n",
       "```\n",
       "\n",
       "### Metadata\n",
       "- **Source URL**: [Fewsats](https://www.fewsats.com/)\n",
       "- **Status Code**: 200\n",
       "\n",
       "If you need more specific information or further assistance, let me know!\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-AIc6IK09Tjhfige61IAekQh8FLNLH\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I successfully scraped the URL https://www.fewsats.com/. Here is the scraped data:\\n\\n### Title\\n**Monetize your Files, Databases**\\n\\n### Content (Markdown)\\n```markdown\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/66475f66cdbcb00d7bf2fd44_Employee%20data.png)\\n\\n[Learn More](#)![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n[Learn More](#)![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/664773c569f5d9dbac6655a0_Employee%20data-2.png)\\n\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/664762e683491e5b21c08f31_Employee%20data-3.png)\\n[Learn More](#)![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n\\nThe L402 protocol builds on top of HTTP and the Lightning network to enable internet-first, machine friendly paywalls.\\n\\nInternet-Native Paywalls\\n\\nThe L402 protocol builds on top of HTTP and the Lightning network to enable internet-first, machine friendly paywalls.\\n\\nL402 is an open protocol that anyone can build upon, fostering a flourishing ecosystem of innovative solutions.\\n\\nAI systems are now key consumers of software, driving demand for more intelligent, contextual data and tools. With one integration, Fewsats unlocks a universe of resources to supercharge these AI consumers.\\n\\n**Revolutionize your bots with Retrieval Augmented Generation (RAG) and in-context information.**\\n```\\n\\n### Metadata\\n- **Source URL**: [Fewsats](https://www.fewsats.com/)\\n- **Status Code**: 200\\n\\nIf you need more specific information or further assistance, let me know!', refusal=None, role='assistant', function_call=None, tool_calls=None))]\n",
       "- created: 1728999726\n",
       "- model: gpt-4o-mini-2024-07-18\n",
       "- object: chat.completion\n",
       "- service_tier: None\n",
       "- system_fingerprint: fp_e2bde53e6e\n",
       "- usage: CompletionUsage(completion_tokens=618, prompt_tokens=1210, total_tokens=1828, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIc6IK09Tjhfige61IAekQh8FLNLH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I successfully scraped the URL https://www.fewsats.com/. Here is the scraped data:\\n\\n### Title\\n**Monetize your Files, Databases**\\n\\n### Content (Markdown)\\n```markdown\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/66475f66cdbcb00d7bf2fd44_Employee%20data.png)\\n\\n[Learn More](#)![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n[Learn More](#)![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/664773c569f5d9dbac6655a0_Employee%20data-2.png)\\n\\n![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/664762e683491e5b21c08f31_Employee%20data-3.png)\\n[Learn More](#)![](https://cdn.prod.website-files.com/6645a4a7082c15bec7e9fd6e/6645a4a7082c15bec7e9fdda_arrow-right-icon.png)\\n\\nThe L402 protocol builds on top of HTTP and the Lightning network to enable internet-first, machine friendly paywalls.\\n\\nInternet-Native Paywalls\\n\\nThe L402 protocol builds on top of HTTP and the Lightning network to enable internet-first, machine friendly paywalls.\\n\\nL402 is an open protocol that anyone can build upon, fostering a flourishing ecosystem of innovative solutions.\\n\\nAI systems are now key consumers of software, driving demand for more intelligent, contextual data and tools. With one integration, Fewsats unlocks a universe of resources to supercharge these AI consumers.\\n\\n**Revolutionize your bots with Retrieval Augmented Generation (RAG) and in-context information.**\\n```\\n\\n### Metadata\\n- **Source URL**: [Fewsats](https://www.fewsats.com/)\\n- **Status Code**: 200\\n\\nIf you need more specific information or further assistance, let me know!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1728999726, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_e2bde53e6e', usage=In: 1210; Out: 618; Total: 1828)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.toolloop(\"can you scrape this url for me: https://www.fewsats.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the full process on how to add a tool to the agent, let's write a single function that encapsulates the entire process. The agent will be able to call this function to add a new tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def add_l402_tool(uri: str) -> str:\n",
    "    \"\"\"Add a new tool to the agent's toolset.\"\"\"\n",
    "    info = get_l402_uri_info(uri)\n",
    "    r = generate_python_function(info)\n",
    "    func_code = extract_function_code(contents(r))\n",
    "\n",
    "    cf = create_func(func_code)\n",
    "    tools.append(cf)\n",
    "    return f\"tool {cf.__name__} added\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = \"\"\"You are a helpful assistant that can add new tools to help users accomplish actions and get information. \n",
    "When a user provides an L402 URI, you should add it as a tool right away. If you do not have any tools, say so if the user asks.\"\"\"\n",
    "model = \"gpt-4o\"\n",
    "tools = [add_l402_tool]\n",
    "chat = Chat(model, sp=sp, tools=tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Received messages:\", messages)\n",
    "msgs = [mk_msg(m['content']) for m in messages[:-1]]\n",
    "print(msgs)\n",
    "chat.h = msgs\n",
    "# Use Cosette's Chat with tool loop, including the conversation history\n",
    "response = chat.toolloop(pr=messages[-1]['content'], trace_func=pchoice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "It seems that I currently don't have any tools available to perform web scraping tasks. If you have an L402 URI for a scraping tool, you can provide it, and I can add it as a tool to assist with your request.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-AIcUgLTGZC3X0PygNiOYnOqjR61Af\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"It seems that I currently don't have any tools available to perform web scraping tasks. If you have an L402 URI for a scraping tool, you can provide it, and I can add it as a tool to assist with your request.\", refusal=None, role='assistant', function_call=None, tool_calls=None))]\n",
       "- created: 1729001238\n",
       "- model: gpt-4o-2024-08-06\n",
       "- object: chat.completion\n",
       "- service_tier: None\n",
       "- system_fingerprint: fp_6b68a8204b\n",
       "- usage: CompletionUsage(completion_tokens=48, prompt_tokens=118, total_tokens=166, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIcUgLTGZC3X0PygNiOYnOqjR61Af', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"It seems that I currently don't have any tools available to perform web scraping tasks. If you have an L402 URI for a scraping tool, you can provide it, and I can add it as a tool to assist with your request.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729001238, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_6b68a8204b', usage=In: 118; Out: 48; Total: 166)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.toolloop(pr='scrape wolfync.com/schedule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'role': 'user', 'content': [{'type': 'text', 'text': 'scrape wolfync.com/schedule'}]}\n",
      "1 ChatCompletionMessage(content=\"It seems that I currently don't have any tools available to perform web scraping tasks. If you have an L402 URI for a scraping tool, you can provide it, and I can add it as a tool to assist with your request.\", refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "def print_history(h):\n",
    "    for i,m in enumerate(h):\n",
    "        print(i,m)\n",
    "\n",
    "print_history(chat.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 500 Server Error: Internal Server Error for url: https://api.fewsats.com/v0/gateway/access/f12e5deb-b07b-4af4-a4f2-3fbf076228a9\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "It seems there was an issue with scraping the website \"https://wolfync.com/schedule\". The response did not return any data. There could be multiple reasons for this, including access restrictions on the website or issues with the scraping tool. If there's anything else you'd like to try or any other assistance you need, feel free to let me know!\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-AIcVCjQm2sUUoWlPudECWE3KRMOCU\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems there was an issue with scraping the website \"https://wolfync.com/schedule\". The response did not return any data. There could be multiple reasons for this, including access restrictions on the website or issues with the scraping tool. If there\\'s anything else you\\'d like to try or any other assistance you need, feel free to let me know!', refusal=None, role='assistant', function_call=None, tool_calls=None))]\n",
       "- created: 1729001270\n",
       "- model: gpt-4o-2024-08-06\n",
       "- object: chat.completion\n",
       "- service_tier: None\n",
       "- system_fingerprint: fp_a20a4ee344\n",
       "- usage: CompletionUsage(completion_tokens=71, prompt_tokens=407, total_tokens=478, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIcVCjQm2sUUoWlPudECWE3KRMOCU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems there was an issue with scraping the website \"https://wolfync.com/schedule\". The response did not return any data. There could be multiple reasons for this, including access restrictions on the website or issues with the scraping tool. If there\\'s anything else you\\'d like to try or any other assistance you need, feel free to let me know!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729001270, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_a20a4ee344', usage=In: 407; Out: 71; Total: 478)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.toolloop(pr='Tool to scrape websites: l402://api.fewsats.com/v0/gateway/f12e5deb-b07b-4af4-a4f2-3fbf076228a9/info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'role': 'user', 'content': [{'type': 'text', 'text': 'scrape wolfync.com/schedule'}]}\n",
      "1 ChatCompletionMessage(content=\"It seems that I currently don't have any tools available to perform web scraping tasks. If you have an L402 URI for a scraping tool, you can provide it, and I can add it as a tool to assist with your request.\", refusal=None, role='assistant', function_call=None, tool_calls=None)\n",
      "2 {'role': 'user', 'content': [{'type': 'text', 'text': 'Tool to scrape websites: l402://api.fewsats.com/v0/gateway/f12e5deb-b07b-4af4-a4f2-3fbf076228a9/info'}]}\n",
      "3 ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_f7BxSCx4CFf3akLngiSK16dV', function=Function(arguments='{\"uri\":\"l402://api.fewsats.com/v0/gateway/f12e5deb-b07b-4af4-a4f2-3fbf076228a9/info\"}', name='add_l402_tool'), type='function')])\n",
      "4 {'role': 'tool', 'content': [{'type': 'text', 'text': 'tool scrape_web_url added'}], 'tool_call_id': 'call_f7BxSCx4CFf3akLngiSK16dV', 'name': 'add_l402_tool'}\n",
      "5 ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_qrIJ5GXIpcP6Kauid2FFXoP4', function=Function(arguments='{\"url\":\"https://wolfync.com/schedule\"}', name='scrape_web_url'), type='function')])\n",
      "6 {'role': 'tool', 'content': [{'type': 'text', 'text': 'None'}], 'tool_call_id': 'call_qrIJ5GXIpcP6Kauid2FFXoP4', 'name': 'scrape_web_url'}\n",
      "7 ChatCompletionMessage(content='It seems there was an issue with scraping the website \"https://wolfync.com/schedule\". The response did not return any data. There could be multiple reasons for this, including access restrictions on the website or issues with the scraping tool. If there\\'s anything else you\\'d like to try or any other assistance you need, feel free to let me know!', refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i,m) for i,m in enumerate(chat.h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = chat.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(model, sp=sp, tools=tools)\n",
    "chat.h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I currently do not have any tools available to perform web scraping. If you can provide an L402 URI, I can add the necessary tool to help accomplish this task.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-AIcXW0woFpKlT3A3OzdfCDLWbKmJE\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I currently do not have any tools available to perform web scraping. If you can provide an L402 URI, I can add the necessary tool to help accomplish this task.', refusal=None, role='assistant', function_call=None, tool_calls=None))]\n",
       "- created: 1729001414\n",
       "- model: gpt-4o-2024-08-06\n",
       "- object: chat.completion\n",
       "- service_tier: None\n",
       "- system_fingerprint: fp_a20a4ee344\n",
       "- usage: CompletionUsage(completion_tokens=35, prompt_tokens=213, total_tokens=248, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIcXW0woFpKlT3A3OzdfCDLWbKmJE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I currently do not have any tools available to perform web scraping. If you can provide an L402 URI, I can add the necessary tool to help accomplish this task.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729001414, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_a20a4ee344', usage=In: 213; Out: 35; Total: 248)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.toolloop(pr='scrape https://www.fewsats.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.h = msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The scraping of \"https://www.fewsats.com/\" was successful. Here's a brief overview of the content:\n",
       "\n",
       "- The website discusses the L402 protocol, which builds on top of HTTP and the Lightning network to enable internet-first, machine-friendly paywalls.\n",
       "- The L402 protocol is an open protocol fostering a flourishing ecosystem of innovative solutions.\n",
       "- There's a focus on AI systems as key consumers of software, driving demand for more intelligent, contextual data and tools. Fewsats' integration helps unlock resources for these AI consumers.\n",
       "- It mentions \"Retrieval Augmented Generation (RAG)\" and the revolutionizing of bots with in-context information.\n",
       "\n",
       "If you're interested in specific details or have any further questions, let me know!\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-AIcY5xu9yHs5R9w8gmOcZ8eTpq8zT\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The scraping of \"https://www.fewsats.com/\" was successful. Here\\'s a brief overview of the content:\\n\\n- The website discusses the L402 protocol, which builds on top of HTTP and the Lightning network to enable internet-first, machine-friendly paywalls.\\n- The L402 protocol is an open protocol fostering a flourishing ecosystem of innovative solutions.\\n- There\\'s a focus on AI systems as key consumers of software, driving demand for more intelligent, contextual data and tools. Fewsats\\' integration helps unlock resources for these AI consumers.\\n- It mentions \"Retrieval Augmented Generation (RAG)\" and the revolutionizing of bots with in-context information.\\n\\nIf you\\'re interested in specific details or have any further questions, let me know!', refusal=None, role='assistant', function_call=None, tool_calls=None))]\n",
       "- created: 1729001449\n",
       "- model: gpt-4o-2024-08-06\n",
       "- object: chat.completion\n",
       "- service_tier: None\n",
       "- system_fingerprint: fp_a20a4ee344\n",
       "- usage: CompletionUsage(completion_tokens=147, prompt_tokens=1379, total_tokens=1526, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIcY5xu9yHs5R9w8gmOcZ8eTpq8zT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The scraping of \"https://www.fewsats.com/\" was successful. Here\\'s a brief overview of the content:\\n\\n- The website discusses the L402 protocol, which builds on top of HTTP and the Lightning network to enable internet-first, machine-friendly paywalls.\\n- The L402 protocol is an open protocol fostering a flourishing ecosystem of innovative solutions.\\n- There\\'s a focus on AI systems as key consumers of software, driving demand for more intelligent, contextual data and tools. Fewsats\\' integration helps unlock resources for these AI consumers.\\n- It mentions \"Retrieval Augmented Generation (RAG)\" and the revolutionizing of bots with in-context information.\\n\\nIf you\\'re interested in specific details or have any further questions, let me know!', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729001449, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_a20a4ee344', usage=In: 1379; Out: 147; Total: 1526)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.toolloop(pr='scrape https://www.fewsats.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=\"It seems that I currently don't have any tools available to perform web scraping tasks. If you have an L402 URI for a scraping tool, you can provide it, and I can add it as a tool to assist with your request.\", refusal=None, role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
